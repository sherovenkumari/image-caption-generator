ğŸ–¼ï¸ Image Caption Generator using CNN and LSTM
ğŸ“Œ Project Overview

    This project implements an Image Caption Generator that automatically generates natural language descriptions for images using Deep Learning.
    It combines CNN-based image feature extraction with a sequence-based language model to predict meaningful captions.

    The project is designed to be simple to moderate level, suitable for training purposes, and runnable on a CPU-only system.

ğŸ¯ Objectives

    To understand how images can be converted into meaningful textual descriptions

    To learn the integration of computer vision and natural language processing

    To build and evaluate a basic end-to-end deep learning pipeline

    To generate captions for unseen images using a trained model

ğŸ§  Model Architecture

    The project follows a two-branch architecture:

        1ï¸âƒ£ Image Feature Extractor (CNN)

            Uses a pretrained CNN model (e.g., VGG16 / similar)

            Extracts a fixed-length feature vector from images

            Features are saved to avoid recomputation

        2ï¸âƒ£ Caption Generator (Sequence Model)

            Uses Embedding + LSTM / Dense layers

            Takes:

            Image features

            Partial caption sequence

            Predicts the next word in the caption

ğŸ“‚ Project Structure

image-caption-generator/
â”‚
â”œâ”€â”€ dataset/
â”‚   â”œâ”€â”€ images/
â”‚   â”‚   â”œâ”€â”€ Flicker8k_Dataset/
â”‚   â”‚   â””â”€â”€ images_300/
â”‚   â””â”€â”€ Text/
â”‚       â””â”€â”€ Flickr8k_text/
â”‚
â”œâ”€â”€ preprocess.py          # Text preprocessing
â”œâ”€â”€ features.py            # Image feature extraction
â”œâ”€â”€ train.py               # Model training
â”œâ”€â”€ model.py               # CNN + Transformer model
â”œâ”€â”€ inference.py           # Caption generation (prediction)
â”œâ”€â”€ image_filter.py        # Dataset filtering utilities
â”œâ”€â”€ dataset_checking.py    # Dataset validation
â”‚
â”œâ”€â”€ image_features.npy     # Pre-extracted image features
â”œâ”€â”€ caption_model.keras    # Trained model
â”‚
â””â”€â”€ README.md

ğŸ“Š Dataset

    Based on Flickr8k dataset

    Custom reduced dataset of 300 images

    Each image is associated with multiple captions

    Dataset is included inside the repository



âš™ï¸ Requirements

    Install dependencies using:

    pip install tensorflow numpy matplotlib pillow nltk


    âš ï¸ Make sure you are using Python 3.8+

ğŸš€ How to Run the Project

    1ï¸âƒ£ Preprocess Text Data
        python preprocess.py

    2ï¸âƒ£ Extract Image Features (Run once)
        python features.py
        This generates:

        image_features.npy

    3ï¸âƒ£ Train the Model
        python train.py

        This saves:
        caption_model.keras

    4ï¸âƒ£ Generate Caption for an Image
        python inference.py

ğŸ§ª Sample Output

    Input Image: dog_running.jpg
    Generated Caption: "a dog is running through the grass"


âš™ï¸ Technologies & Libraries Used

    Python 3.x

    TensorFlow / Keras

    NumPy

    Matplotlib

    Pickle

    Pillow (PIL)

ğŸ‹ï¸ Training Details

    Loss Function: Categorical Crossentropy

    Optimizer: Adam

    Metrics: Accuracy (token-level)

    Epochs: Configurable (CPU-friendly)

    Validation Split: 20%

    Metrics Observed

    Training Loss â†“

    Validation Loss â†“

    Training Accuracy â†‘

    Validation Accuracy â†‘

    Note: Accuracy is token-level due to sequence prediction nature.

ğŸ“ˆ Model Evaluation

    Loss Curve: Shows learning convergence

    Accuracy Curve: Indicates word prediction improvement

    Qualitative Evaluation: Visual inspection of generated captions

ğŸ§ª Inference Example

    For a given input image, the model:

    Extracts image features

    Generates caption word-by-word

    Displays the image with the predicted caption

Sample Output:

Generated Caption: a brown and white dog is playing with a toy

ğŸ’» System Requirements

    CPU-based system (no GPU required)

    Minimum 8 GB RAM

    Windows / Linux / macOS

ğŸ“ˆ Future Improvements

    Add BLEU score evaluation

    Support larger datasets (Flickr30k / MS-COCO)

    Integrate attention visualization

    Web or GUI interface


âš ï¸ Limitations

    Small dataset (300 images)

    CPU-only training

    Limited vocabulary

    Captions may repeat words or lack grammatical perfection

    These limitations are acceptable for training-level implementation.

ğŸ‘©â€ğŸ’» Author

    Sheroven Kumari
    Deep Learning Project â€“ Image Caption Generator

ğŸ“œ License

    This project is for educational and research purposes only.